{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### written by Scott McCain, June 2019\n",
    "### Code audit done: June 26, 2019.\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the following columns to numeric: Index(['GOS_927_0_1G_S63_L005_001', 'GOS_927_0_8G_S62_L005_001',\n",
      "       'GOS_927_3_0G_S61_L005_001', 'GOS_930_0_1G_S66_L005_001',\n",
      "       'GOS_930_0_8G_S65_L005_001', 'GOS_930_3_0G_S64_L005_001',\n",
      "       'GOS_933_0_1G_S69_L005_001', 'GOS_933_0_8G_S68_L005_001',\n",
      "       'GOS_933_3_0G_S67_L005_001', 'GOS_935_0_1G_S72_L005_001',\n",
      "       'GOS_935_0_8G_S71_L005_001', 'GOS_935_3_0G_S70_L005_001'],\n",
      "      dtype='object')\n",
      "Converting the following columns to numeric: Index(['GOS_927_0_1T_S75_L006_001', 'GOS_927_0_8T_S74_L006_001',\n",
      "       'GOS_927_3_0T_S73_L006_001', 'GOS_929_0_1T_S78_L006_001',\n",
      "       'GOS_929_0_8T_S77_L006_001', 'GOS_929_3_0T_S76_L006_001',\n",
      "       'GOS_930_0_1T_S81_L006_001', 'GOS_930_0_8T_S80_L006_001',\n",
      "       'GOS_930_3_0T_S79_L006_001', 'GOS_932_0_1T_S84_L006_001',\n",
      "       'GOS_932_0_8T_S83_L006_001', 'GOS_932_3_0T_S82_L006_001',\n",
      "       'GOS_933_0_1T_S87_L006_001', 'GOS_933_0_8T_S86_L006_001',\n",
      "       'GOS_933_3_0T_S85_L006_001', 'GOS_935_0_1T_S90_L006_001',\n",
      "       'GOS_935_0_8T_S89_L006_001', 'GOS_935_3_0T_S88_L006_001'],\n",
      "      dtype='object')\n",
      "Converting the following columns to numeric: Index(['TFG_t0_A', 'TFG_t0_B', 'TFG_t0_C'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read in the annotation tab files\n",
    "\n",
    "def read_in_annot(file_in):\n",
    "    '''\n",
    "    # function to read in the annotation file (.tab) associated with the sequence file\n",
    "    '''\n",
    "    # make a list of annotation lines\n",
    "    annot_list = []\n",
    "    # open file\n",
    "    with open(file_in,\n",
    "             newline = '') as meta_annot:\n",
    "        annot_reader = csv.reader(meta_annot, delimiter='\\t')\n",
    "        for meta_annot in annot_reader:\n",
    "            # add each annotation line to the list\n",
    "            annot_list.append(meta_annot) \n",
    "    # convert the list into a pd dataframe\n",
    "    annot_df = DataFrame.from_records(annot_list[1:], columns = annot_list[0])\n",
    "    # format the columns of numbers correctly:\n",
    "    return annot_df\n",
    "\n",
    "# tester = read_in_annot(file_in = '../data/metaGT/AAHZ_L5_ANT_pool1_MetaG/metag_annotation_all.filtered.grps.LPI.RPKMs.GO.tab')\n",
    "\n",
    "def read_and_format(file_in, column_low, column_high):\n",
    "    '''\n",
    "    reads in using the above function, and converts columns to numeric\n",
    "    '''\n",
    "    if 'tab' in file_in:\n",
    "        unformat_df = read_in_annot(file_in = file_in)\n",
    "    if 'xlsx' in file_in:\n",
    "        unformat_df = pd.read_excel(file_in)\n",
    "    cols_to_convert = unformat_df.columns[column_low:column_high]\n",
    "    print('Converting the following columns to numeric:', cols_to_convert)\n",
    "    unformat_df[cols_to_convert] = unformat_df[cols_to_convert].apply(pd.to_numeric, \n",
    "                                                               errors = 'coerce')\n",
    "    # for each col to convert, go in an ensure that the minimum is greater than zero\n",
    "    for i in range(len(cols_to_convert)):\n",
    "        col_min = unformat_df[cols_to_convert[i]].min()\n",
    "        if col_min < 0:\n",
    "            raise ValueError('Are you sure you chose the right columns? Seems that they dont go 0 to 1')\n",
    "    return unformat_df\n",
    "\n",
    "\n",
    "metag_df = read_and_format(file_in = '../data/metaGT/AAHZ_L5_ANT_pool1_MetaG/metag_annotation_all.filtered.grps.LPI.RPKMs.GO.tab',\n",
    "                          column_low = 35, column_high = 47)\n",
    "metat_df = read_and_format(file_in = '../data/metaGT/AAHZ_L6_ANT_pool2_MetaT/metat_annotation_all.filtered.grps.LPI.RPKMs.GO.tab',\n",
    "                          column_low = 35, column_high = 53)\n",
    "tfg_df = read_and_format(file_in = '../data/mcmurdo-metatrans/Bertrand_McCrow_TFG/annotation_allTFG.grpnorm_mmetsp_fc_pn_reclassified.edgeR.xlsx',\n",
    "                        column_low = 46, column_high = 49)\n",
    "\n",
    "# # read in meta G\n",
    "# metag_list = []\n",
    "# with open('../data/metaGT/AAHZ_L5_ANT_pool1_MetaG/metag_annotation_all.filtered.grps.LPI.RPKMs.GO.tab',\n",
    "#          newline = '') as metag_annot:\n",
    "#     metag_annot_reader = csv.reader(metag_annot, delimiter='\\t')\n",
    "#     for metag_annot in metag_annot_reader:\n",
    "#         metag_list.append(metag_annot)\n",
    "# # convert the list into a pd dataframe\n",
    "# metag_df = DataFrame.from_records(metag_list)\n",
    "# tester = metag_list[1:]\n",
    "# tester2 = DataFrame.from_records(tester, columns=metag_list[0])\n",
    "\n",
    "# # read in meta T\n",
    "# metat_list = []\n",
    "# with open('../data/metaGT/AAHZ_L6_ANT_pool2_MetaT/metat_annotation_all.filtered.grps.LPI.RPKMs.GO.tab',\n",
    "#          newline = '') as metat_annot:\n",
    "#     metat_annot_reader = csv.reader(metat_annot, delimiter='\\t')\n",
    "#     for metat_annot in metat_annot_reader:\n",
    "#         metat_list.append(metat_annot)\n",
    "# # convert the list into a pd dataframe\n",
    "# metat_df = DataFrame.from_records(metat_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the all assembly files\n",
    "def read_in_seqs(file_in):\n",
    "    seq_vec = []\n",
    "    orf_vec = []\n",
    "    for seq_record in SeqIO.parse(file_in, 'fasta'):\n",
    "        seq_vec.append(seq_record.seq)\n",
    "        orf_vec.append(seq_record.id)\n",
    "    if len(seq_vec) != len(orf_vec):\n",
    "        raise ValueError('Something seems odd? The ORF vector length is greater than the sequence vector.')\n",
    "    # making a dictionary of values, where the keys are ORF ID's and the sequences are the values\n",
    "    return_dict = dict(zip(orf_vec, seq_vec))\n",
    "    return return_dict\n",
    "\n",
    "# read in meta G faa\n",
    "metag_seqs = read_in_seqs(file_in = '../data/metaGT/AAHZ_L5_ANT_pool1_MetaG/assembly_all/metag_assembly.orf.faa')\n",
    "\n",
    "# read in meta T faa\n",
    "metat_seqs = read_in_seqs(file_in = '../data/metaGT/AAHZ_L6_ANT_pool2_MetaT/assembly_all/metat_assembly.orf.faa')\n",
    "\n",
    "# read in TFG metaT\n",
    "tfg_seqs = read_in_seqs(file_in = '../data/mcmurdo-metatrans/assembly.orf.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOS_927_0_1T_S75_L006_001</th>\n",
       "      <th>GOS_927_0_8T_S74_L006_001</th>\n",
       "      <th>GOS_927_3_0T_S73_L006_001</th>\n",
       "      <th>GOS_929_0_1T_S78_L006_001</th>\n",
       "      <th>GOS_929_0_8T_S77_L006_001</th>\n",
       "      <th>GOS_929_3_0T_S76_L006_001</th>\n",
       "      <th>GOS_930_0_1T_S81_L006_001</th>\n",
       "      <th>GOS_930_0_8T_S80_L006_001</th>\n",
       "      <th>GOS_930_3_0T_S79_L006_001</th>\n",
       "      <th>GOS_932_0_1T_S84_L006_001</th>\n",
       "      <th>GOS_932_0_8T_S83_L006_001</th>\n",
       "      <th>GOS_932_3_0T_S82_L006_001</th>\n",
       "      <th>GOS_933_0_1T_S87_L006_001</th>\n",
       "      <th>GOS_933_0_8T_S86_L006_001</th>\n",
       "      <th>GOS_933_3_0T_S85_L006_001</th>\n",
       "      <th>GOS_935_0_1T_S90_L006_001</th>\n",
       "      <th>GOS_935_0_8T_S89_L006_001</th>\n",
       "      <th>GOS_935_3_0T_S88_L006_001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.00000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.000000</td>\n",
       "      <td>87162.00000</td>\n",
       "      <td>87162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.531291</td>\n",
       "      <td>13.954075</td>\n",
       "      <td>8.309466</td>\n",
       "      <td>14.543993</td>\n",
       "      <td>13.092815</td>\n",
       "      <td>6.829812</td>\n",
       "      <td>14.925158</td>\n",
       "      <td>14.238469</td>\n",
       "      <td>13.112753</td>\n",
       "      <td>14.33845</td>\n",
       "      <td>14.851799</td>\n",
       "      <td>13.712626</td>\n",
       "      <td>14.803767</td>\n",
       "      <td>13.969085</td>\n",
       "      <td>11.312234</td>\n",
       "      <td>14.798458</td>\n",
       "      <td>13.67389</td>\n",
       "      <td>8.552823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>190.118185</td>\n",
       "      <td>115.116746</td>\n",
       "      <td>96.970095</td>\n",
       "      <td>172.648194</td>\n",
       "      <td>109.133300</td>\n",
       "      <td>59.804126</td>\n",
       "      <td>120.159475</td>\n",
       "      <td>84.136698</td>\n",
       "      <td>118.361058</td>\n",
       "      <td>77.20987</td>\n",
       "      <td>73.503325</td>\n",
       "      <td>81.464777</td>\n",
       "      <td>145.112303</td>\n",
       "      <td>83.338751</td>\n",
       "      <td>233.035375</td>\n",
       "      <td>136.171317</td>\n",
       "      <td>67.22852</td>\n",
       "      <td>141.869407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.75000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.670000</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>6.370000</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>4.630000</td>\n",
       "      <td>10.02000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>7.550000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.780000</td>\n",
       "      <td>10.12000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36569.630000</td>\n",
       "      <td>10892.760000</td>\n",
       "      <td>10794.510000</td>\n",
       "      <td>34017.800000</td>\n",
       "      <td>17978.060000</td>\n",
       "      <td>14434.730000</td>\n",
       "      <td>11555.710000</td>\n",
       "      <td>7638.750000</td>\n",
       "      <td>21520.100000</td>\n",
       "      <td>9916.01000</td>\n",
       "      <td>4440.270000</td>\n",
       "      <td>5472.080000</td>\n",
       "      <td>13659.180000</td>\n",
       "      <td>6189.630000</td>\n",
       "      <td>53429.230000</td>\n",
       "      <td>17011.550000</td>\n",
       "      <td>11836.01000</td>\n",
       "      <td>33728.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GOS_927_0_1T_S75_L006_001  GOS_927_0_8T_S74_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   15.531291                  13.954075   \n",
       "std                   190.118185                 115.116746   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.250000                   0.780000   \n",
       "75%                     5.670000                   6.240000   \n",
       "max                 36569.630000               10892.760000   \n",
       "\n",
       "       GOS_927_3_0T_S73_L006_001  GOS_929_0_1T_S78_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                    8.309466                  14.543993   \n",
       "std                    96.970095                 172.648194   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   1.600000   \n",
       "75%                     0.000000                   8.260000   \n",
       "max                 10794.510000               34017.800000   \n",
       "\n",
       "       GOS_929_0_8T_S77_L006_001  GOS_929_3_0T_S76_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   13.092815                   6.829812   \n",
       "std                   109.133300                  59.804126   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.450000                   0.000000   \n",
       "50%                     2.120000                   1.120000   \n",
       "75%                     6.860000                   4.970000   \n",
       "max                 17978.060000               14434.730000   \n",
       "\n",
       "       GOS_930_0_1T_S81_L006_001  GOS_930_0_8T_S80_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   14.925158                  14.238469   \n",
       "std                   120.159475                  84.136698   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     1.220000                   1.460000   \n",
       "75%                     6.370000                   7.560000   \n",
       "max                 11555.710000                7638.750000   \n",
       "\n",
       "       GOS_930_3_0T_S79_L006_001  GOS_932_0_1T_S84_L006_001  \\\n",
       "count               87162.000000                87162.00000   \n",
       "mean                   13.112753                   14.33845   \n",
       "std                   118.361058                   77.20987   \n",
       "min                     0.000000                    0.00000   \n",
       "25%                     0.000000                    0.00000   \n",
       "50%                     0.000000                    2.26000   \n",
       "75%                     4.630000                   10.02000   \n",
       "max                 21520.100000                 9916.01000   \n",
       "\n",
       "       GOS_932_0_8T_S83_L006_001  GOS_932_3_0T_S82_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   14.851799                  13.712626   \n",
       "std                    73.503325                  81.464777   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.630000                   0.000000   \n",
       "50%                     3.020000                   1.930000   \n",
       "75%                     9.200000                   7.550000   \n",
       "max                  4440.270000                5472.080000   \n",
       "\n",
       "       GOS_933_0_1T_S87_L006_001  GOS_933_0_8T_S86_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   14.803767                  13.969085   \n",
       "std                   145.112303                  83.338751   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     1.860000                   1.170000   \n",
       "75%                     7.100000                   7.670000   \n",
       "max                 13659.180000                6189.630000   \n",
       "\n",
       "       GOS_933_3_0T_S85_L006_001  GOS_935_0_1T_S90_L006_001  \\\n",
       "count               87162.000000               87162.000000   \n",
       "mean                   11.312234                  14.798458   \n",
       "std                   233.035375                 136.171317   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     0.000000                   1.700000   \n",
       "75%                     0.000000                   7.780000   \n",
       "max                 53429.230000               17011.550000   \n",
       "\n",
       "       GOS_935_0_8T_S89_L006_001  GOS_935_3_0T_S88_L006_001  \n",
       "count                87162.00000               87162.000000  \n",
       "mean                    13.67389                   8.552823  \n",
       "std                     67.22852                 141.869407  \n",
       "min                      0.00000                   0.000000  \n",
       "25%                      0.00000                   0.000000  \n",
       "50%                      2.75000                   0.000000  \n",
       "75%                     10.12000                   0.000000  \n",
       "max                  11836.01000               33728.070000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tester = get_sample_specific_orfs(column_to_select1 = 'GOS_927_0_1G_S63_L005_001', df1 = metag_df,\n",
    "#                        column_to_select2 = 'GOS_927_0_1T_S75_L006_001', df2 = metat_df)\n",
    "\n",
    "type(metag_df['GOS_927_0_1G_S63_L005_001'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the orfs based on the column completeness for a given sample ID\n",
    "         \n",
    "# def get_sample_specific_orfs(column_to_select1, df1, \n",
    "#                              column_to_select2, df2):\n",
    "    \n",
    "# #     column_to_select1 = 'GOS_927_0_1G_S63_L005_001'\n",
    "#     # boolean which of this column is greater than 0\n",
    "#     # return the orf_id values from that\n",
    "#     print('Finding ORFs present...')\n",
    "#     orfs_present1 = df1[df1[column_to_select1] > 0]['orf_id'].tolist()\n",
    "#     orfs_present2 = df2[df2[column_to_select2] > 0]['orf_id'].tolist()\n",
    "#     return [orfs_present1, orfs_present2]\n",
    "\n",
    "\n",
    "def get_sample_specific_orfs(column_to_select1, df1, \n",
    "                             column_to_select2, df2):\n",
    "    \n",
    "    ## this function goes into the master df and returns orfs which were present in a given sample\n",
    "    \n",
    "    print('Finding ORFs present...')\n",
    "    \n",
    "    if df2 is None or column_to_select2 is None:\n",
    "        ## selected only one dataframe to subsample from\n",
    "        orfs_present1_redundant = []\n",
    "        for column_i in range(len(column_to_select1)):\n",
    "\n",
    "            orfs_present1_temp = df1[df1[column_to_select1[column_i]] > 0]['orf_id'].tolist()\n",
    "            orfs_present1_redundant = orfs_present1_temp + orfs_present1_redundant\n",
    "        \n",
    "        orfs_present1 = list(set(orfs_present1_redundant))\n",
    "        \n",
    "        return [orfs_present1]\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if isinstance(column_to_select1, str):\n",
    "            print('One column for each df selected...')\n",
    "            orfs_present1 = df1[df1[column_to_select1] > 0]['orf_id'].tolist()\n",
    "            orfs_present2 = df2[df2[column_to_select2] > 0]['orf_id'].tolist()\n",
    "\n",
    "        if isinstance(column_to_select1, list):\n",
    "            print('Multiple columns for each df selected...')\n",
    "\n",
    "            orfs_present1_redundant = []\n",
    "            for column_i in range(len(column_to_select1)):\n",
    "\n",
    "                orfs_present1_temp = df1[df1[column_to_select1[column_i]] > 0]['orf_id'].tolist()\n",
    "                orfs_present1_redundant = orfs_present1_temp + orfs_present1_redundant\n",
    "\n",
    "            orfs_present2_redundant = []\n",
    "            for column_i in range(len(column_to_select2)):\n",
    "                orfs_present2_temp = df2[df2[column_to_select2[column_i]] > 0]['orf_id'].tolist()\n",
    "                orfs_present2_redundant = orfs_present2_temp + orfs_present2_redundant\n",
    "\n",
    "            orfs_present1 = list(set(orfs_present1_redundant))\n",
    "            orfs_present2 = list(set(orfs_present2_redundant))\n",
    "\n",
    "        return [orfs_present1, orfs_present2]\n",
    "\n",
    "# tester = get_sample_specific_orfs(column_to_select1 = ['TFG_t0_A', 'TFG_t0_B', 'TFG_t0_C'], \n",
    "#                                   df1 = tfg_df, \n",
    "#                                   column_to_select2 = None, df2 = None)\n",
    "    \n",
    "# tester = get_sample_specific_orfs(column_to_select1 = 'GOS_927_0_1G_S63_L005_001', df1 = metag_df,\n",
    "#                        column_to_select2 = 'GOS_927_0_1T_S75_L006_001', df2 = metat_df)\n",
    "\n",
    "\n",
    "# tester = get_sample_specific_orfs(column_to_select1 = ['GOS_927_0_1G_S63_L005_001', \n",
    "#                                                        'GOS_935_0_1G_S72_L005_001'], df1 = metag_df,\n",
    "#                         column_to_select2 = ['GOS_927_0_1T_S75_L006_001',\n",
    "#                                              'GOS_935_0_1T_S90_L006_001'], df2 = metat_df)\n",
    "\n",
    "def merge_dict(dict1, dict2):\n",
    "    return dict2.update(dict1)\n",
    "\n",
    "# function to subsample the master sample and return a list of dictionaries that contain the new data\n",
    "# def subsample_master_assembly(orfs_present_lists, assembly1, assembly2):\n",
    "    \n",
    "# #     assembly1 = metat_seqs\n",
    "# #     assembly2 = metag_seqs\n",
    "# #     orfs_present_list1 = tester[0]\n",
    "# #     orfs_present_list2 = tester[1]\n",
    "#     orfs_present_list1 = orfs_present_lists[0]\n",
    "#     orfs_present_list2 = orfs_present_lists[1]\n",
    "    \n",
    "#     copy_dict1 = dict(assembly1)\n",
    "#     for (key, value) in copy_dict1.items():\n",
    "#         if key not in orfs_present_list1:\n",
    "#             del assembly1[key]\n",
    "\n",
    "#     copy_dict2 = dict(assembly2)\n",
    "#     for (key, value) in copy_dict2.items():\n",
    "#         if key not in orfs_present_list2:\n",
    "#             del assembly2[key]\n",
    "    \n",
    "#     merged_dicts = merge_dict(dict1=assembly1, dict2=assembly2)\n",
    "\n",
    "#     return [assembly1, assembly2]\n",
    "\n",
    "# test_subsample = subsample_master_assembly(orfs_present_lists=tester,\n",
    "#                                           assembly1=metag_seqs,\n",
    "#                                           assembly2=metat_seqs)\n",
    "# the above function seems to work, but it takes a while. instead of subsampling the master,\n",
    "# by looping through each entry to see if it's in the orfs_present_list, it might be faster\n",
    "# to go through the orfs_present_list and grab the elements of the dictionary that correspond to these\n",
    "# orfs, and then output that.\n",
    "\n",
    "def collect_from_master_assembly(orfs_present_lists, assembly_list):\n",
    "    print('Collecting ORFs from master assembly, this step takes time...')\n",
    "#     assembly_list = [assembly1, assembly2]\n",
    "\n",
    "    subsample_sequences = []\n",
    "    subsample_orf_ids = []\n",
    "    \n",
    "    # go through each ORF ID list \n",
    "    print(len(orfs_present_lists))\n",
    "    for orf_present_list_i in range(len(orfs_present_lists)):\n",
    "        # get the ith ORF ID list and the ith Assembly file\n",
    "        single_orf_list = orfs_present_lists[orf_present_list_i]\n",
    "        assembly_i = assembly_list[orf_present_list_i]\n",
    "        \n",
    "        # for each ORF, file it in the assembly file, and ad it to the subsample sequence file\n",
    "        for orf_i in range(len(single_orf_list)):\n",
    "            # find the sequence based on the key of the dictionary of the assembly\n",
    "            target_seq = assembly_i[single_orf_list[orf_i]]\n",
    "            subsample_sequences.append(target_seq)\n",
    "            subsample_orf_ids.append(single_orf_list[orf_i])\n",
    "            \n",
    "        if len(subsample_sequences) != len(subsample_orf_ids):\n",
    "            raise ValueError('A very specific bad thing happened, not sure why..')\n",
    "    \n",
    "    return [subsample_sequences, subsample_orf_ids]\n",
    "            \n",
    "\n",
    "\n",
    "# function to take these dictionaries and write one fasta file with them\n",
    "def write_fasta_file(subsample_output, fasta_name_in):\n",
    "    \n",
    "    fasta_name = str(fasta_name_in) + '.fasta'\n",
    "    \n",
    "    if fasta_name[-5:] != 'fasta':\n",
    "        raise NameError('file input name does not have proper ending')\n",
    "    \n",
    "    print('Writing fasta file...')\n",
    "    with open(fasta_name, 'w') as ofile:\n",
    "        for i in range(len(subsample_output[0])):\n",
    "            ofile.write(\">\" + str(subsample_output[1][i]) + \"\\n\" + str(subsample_output[0][i]) + \"\\n\")\n",
    "    ofile.close()\n",
    "\n",
    "\n",
    "def check_list_of_names(name_list):\n",
    "    print(name_list)\n",
    "    sub_flat_list = []\n",
    "    for i in range(len(name_list)):\n",
    "        sub_flat_list.append(name_list[i][8:11])\n",
    "    unique_elements = list(set(sub_flat_list))\n",
    "    print(unique_elements)\n",
    "    if len(unique_elements) > 1:\n",
    "        raise NameError('houston, you have a problem. Are you sure the input files are all from the same size fraction?')\n",
    "        \n",
    "        \n",
    "def check_names(name_1, name_2):\n",
    "    \n",
    "    if isinstance(name_1, str):\n",
    "        name_1_sub = name_1[0:11]\n",
    "        name_2_sub = name_2[0:11]\n",
    "    \n",
    "    if isinstance(name_1, list):\n",
    "        # check that the samples are all of the sample size class\n",
    "#         check_list_of_names(name_2)\n",
    "#         check_list_of_names(name_1)\n",
    "        \n",
    "        # make a return name\n",
    "        name_1_sub = 'GOS_' + str(name_1[0][8:11])\n",
    "        name_2_sub = 'GOS_' + str(name_2[0][8:11])\n",
    "\n",
    "    print('saving to file name:', name_1_sub)\n",
    "    if name_1_sub != name_2_sub:\n",
    "        raise NameError('Input files for transcriptomic does not match genomic, eek!')\n",
    "    \n",
    "    return name_1_sub\n",
    "\n",
    "def write_multi_fastas(list_of_column_names, df1, df2, assembly_list):\n",
    "    # loop through each element of the list, which is also a 2-element list of the two columns\n",
    "    # that are subsampled\n",
    "    for pair_of_columns in range(len(list_of_column_names)):\n",
    "        \n",
    "        column_name_1 = list_of_column_names[pair_of_columns][0]\n",
    "        column_name_2 = list_of_column_names[pair_of_columns][1]\n",
    "        \n",
    "        file_name_to_save = check_names(name_1 = column_name_1,\n",
    "                                       name_2 = column_name_2)\n",
    "        \n",
    "        sample_orf_lists = get_sample_specific_orfs(column_to_select1 = column_name_1, \n",
    "                                                    df1 = df1, \n",
    "                                                    column_to_select2 = column_name_2, \n",
    "                                                    df2 = df2)\n",
    "        subsampled_for_fasta = collect_from_master_assembly(orfs_present_lists = sample_orf_lists, \n",
    "                                                            assembly_list = assembly_list)\n",
    "        write_fasta_file(subsample_output = subsampled_for_fasta, \n",
    "                         fasta_name_in = file_name_to_save)\n",
    "        \n",
    "def write_one_fasta(list_of_column_names, df1, assembly_list, custom_name):\n",
    "    found_orfs = get_sample_specific_orfs(column_to_select1 = list_of_column_names, \n",
    "                                      df1 = df1, \n",
    "                                      column_to_select2 = None, \n",
    "                                      df2 = None)\n",
    "    subsample_orfs = collect_from_master_assembly(orfs_present_lists=found_orfs,\n",
    "                                              assembly_list=assembly_list)\n",
    "    write_fasta_file(subsample_orfs, fasta_name_in = custom_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to file name: GOS_0_1\n",
      "Finding ORFs present...\n",
      "Multiple columns for each df selected...\n",
      "Collecting ORFs from master assembly, this step takes time...\n",
      "2\n",
      "Writing fasta file...\n",
      "saving to file name: GOS_0_8\n",
      "Finding ORFs present...\n",
      "Multiple columns for each df selected...\n",
      "Collecting ORFs from master assembly, this step takes time...\n",
      "2\n",
      "Writing fasta file...\n",
      "saving to file name: GOS_3_0\n",
      "Finding ORFs present...\n",
      "Multiple columns for each df selected...\n",
      "Collecting ORFs from master assembly, this step takes time...\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-b8fca97c563f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetag_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m               \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetat_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m               assembly_list = [metag_seqs, metat_seqs])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-4f8066331554>\u001b[0m in \u001b[0;36mwrite_multi_fastas\u001b[0;34m(list_of_column_names, df1, df2, assembly_list)\u001b[0m\n\u001b[1;32m    197\u001b[0m                                                     df2 = df2)\n\u001b[1;32m    198\u001b[0m         subsampled_for_fasta = collect_from_master_assembly(orfs_present_lists = sample_orf_lists, \n\u001b[0;32m--> 199\u001b[0;31m                                                             assembly_list = assembly_list)\n\u001b[0m\u001b[1;32m    200\u001b[0m         write_fasta_file(subsample_output = subsampled_for_fasta, \n\u001b[1;32m    201\u001b[0m                          fasta_name_in = file_name_to_save)\n",
      "\u001b[0;32m<ipython-input-103-4f8066331554>\u001b[0m in \u001b[0;36mcollect_from_master_assembly\u001b[0;34m(orfs_present_lists, assembly_list)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0morf_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_orf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# find the sequence based on the key of the dictionary of the assembly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembly_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msingle_orf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morf_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0msubsample_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0msubsample_orf_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_orf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morf_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    \n",
    "# list of columns (sample IDs) that pair up the metagenomic and metatranscriptomic sequences\n",
    "# for creating fasta files\n",
    "column_pair_list = [['GOS_927_0_1G_S63_L005_001', 'GOS_927_0_1T_S75_L006_001'], \n",
    "                     ['GOS_927_0_8G_S62_L005_001', 'GOS_927_0_8T_S74_L006_001'], \n",
    "                     ['GOS_927_3_0G_S61_L005_001', 'GOS_927_3_0T_S73_L006_001'], \n",
    "                     ['GOS_930_0_1G_S66_L005_001', 'GOS_930_0_1T_S81_L006_001'],\n",
    "                     ['GOS_930_0_8G_S65_L005_001', 'GOS_930_0_8T_S80_L006_001'],\n",
    "                     ['GOS_930_3_0G_S64_L005_001', 'GOS_930_3_0T_S79_L006_001'],\n",
    "                     ['GOS_933_0_1G_S69_L005_001', 'GOS_933_0_1T_S87_L006_001'],\n",
    "                     ['GOS_933_0_8G_S68_L005_001', 'GOS_933_0_8T_S86_L006_001'],\n",
    "                     ['GOS_933_3_0G_S67_L005_001', 'GOS_933_3_0T_S85_L006_001'],\n",
    "                     ['GOS_935_0_1G_S72_L005_001', 'GOS_935_0_1T_S90_L006_001'],\n",
    "                     ['GOS_935_0_8G_S71_L005_001', 'GOS_935_0_8T_S89_L006_001'],\n",
    "                     ['GOS_935_3_0G_S70_L005_001', 'GOS_935_3_0T_S88_L006_001']]    \n",
    "\n",
    "# make the column pair list that has pooled samples\n",
    "column_pair_list_pooled = [[['GOS_927_0_1G_S63_L005_001','GOS_930_0_1G_S66_L005_001',\n",
    "                             'GOS_933_0_1G_S69_L005_001','GOS_935_0_1G_S72_L005_001'],\n",
    "                             ['GOS_927_0_1T_S75_L006_001', 'GOS_930_0_1T_S81_L006_001',\n",
    "                             'GOS_933_0_1T_S87_L006_001', 'GOS_935_0_1T_S90_L006_001']],\n",
    "                           [['GOS_927_0_8G_S62_L005_001', 'GOS_930_0_8G_S65_L005_001',\n",
    "                            'GOS_933_0_8G_S68_L005_001', 'GOS_935_0_8G_S71_L005_001'],\n",
    "                           ['GOS_927_0_8T_S74_L006_001', 'GOS_930_0_8T_S80_L006_001',\n",
    "                           'GOS_933_0_8T_S86_L006_001', 'GOS_935_0_8T_S89_L006_001']],\n",
    "                           [['GOS_927_3_0G_S61_L005_001', 'GOS_930_3_0G_S64_L005_001', \n",
    "                            'GOS_933_3_0G_S67_L005_001', 'GOS_935_3_0G_S70_L005_001'],\n",
    "                           ['GOS_927_3_0T_S73_L006_001', 'GOS_930_3_0T_S79_L006_001', \n",
    "                           'GOS_933_3_0T_S85_L006_001', 'GOS_935_3_0T_S88_L006_001']]]\n",
    "\n",
    "write_multi_fastas(list_of_column_names = column_pair_list, \n",
    "                  df1 = metag_df, \n",
    "                  df2 = metat_df, \n",
    "                  assembly1 = metag_seqs,\n",
    "                  assembly2 = metat_seqs)\n",
    "\n",
    "write_multi_fastas(list_of_column_names = column_pair_list_pooled, \n",
    "                  df1 = metag_df, \n",
    "                  df2 = metat_df, \n",
    "                  assembly_list = [metag_seqs, metat_seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding ORFs present...\n",
      "Collecting ORFs from master assembly, this step takes time...\n",
      "1\n",
      "Writing fasta file...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make the column pair list that has pooled samples\n",
    "column_tfg_list = ['TFG_t0_A', 'TFG_t0_B', 'TFG_t0_C']\n",
    "# fetching from the same dataframe, since it's just metaT and I don't want to make the above code more flexible\n",
    "write_one_fasta(list_of_column_names = column_tfg_list, \n",
    "                  df1 = tfg_df, assembly_list = [tfg_seqs], custom_name = \"tfg_t0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the naming convention was built for the sample specific databases\n",
    "# manually rename this one:\n",
    "os.rename('GOS_.fasta', 'tfg_t0.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318965"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = tfg_df[tfg_df['TFG_t0_A'] > 0]['orf_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
